{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":9420055,"sourceType":"datasetVersion","datasetId":5721479}],"dockerImageVersionId":30777,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":5,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# importing required libraries","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nimport os\nimport tensorflow as tf","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Integer labels","metadata":{}},{"cell_type":"markdown","source":"# importing images from folder","metadata":{}},{"cell_type":"code","source":"base_dir = \"/kaggle/input/brain-tumor/Brain-tumer\" # Base path to data directory\ncategories = ['no_tumor', 'glioma_tumor', 'meningioma_tumor', 'pituitary_tumor'] # categories\nlabel_map = {\n    'no_tumor': 0,\n    'glioma_tumor': 1,\n    'meningioma_tumor': 2,\n    'pituitary_tumor': 3\n}# dictionary for category and corresponding integer","metadata":{"execution":{"iopub.status.busy":"2024-09-28T11:21:41.118851Z","iopub.execute_input":"2024-09-28T11:21:41.119266Z","iopub.status.idle":"2024-09-28T11:21:41.123221Z","shell.execute_reply.started":"2024-09-28T11:21:41.119238Z","shell.execute_reply":"2024-09-28T11:21:41.122572Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"# Function for loading images","metadata":{}},{"cell_type":"code","source":"def load_images(base_dir,label_map):\n    images=[]\n    labels=[]\n    for category in categories:\n        category_path=os.path.join(base_dir,category)\n        label=label_map[category]\n\n        # listing every file in perticular directory\n        for filename in os.listdir(category_path):\n            # check file extension\n            if (filename.endswith(\".jpg\") or filename.endswith(\".jpeg\") or filename.endswith(\".png\")):\n                image_path = os.path.join(category_path,filename)\n                images.append(image_path)\n                labels.append(label)\n    return images,labels\n        \nimages,labels=load_images(base_dir,label_map)","metadata":{"execution":{"iopub.status.busy":"2024-09-28T11:21:41.123945Z","iopub.execute_input":"2024-09-28T11:21:41.124177Z","iopub.status.idle":"2024-09-28T11:21:44.710220Z","shell.execute_reply.started":"2024-09-28T11:21:41.124154Z","shell.execute_reply":"2024-09-28T11:21:44.709476Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"# Combine shuffle and seperate","metadata":{}},{"cell_type":"code","source":"combined = list(zip(images, labels))\nnp.random.shuffle(combined)\nimages, labels = zip(*combined)\nprint(images[0])","metadata":{"execution":{"iopub.status.busy":"2024-09-28T11:21:44.711880Z","iopub.execute_input":"2024-09-28T11:21:44.712320Z","iopub.status.idle":"2024-09-28T11:21:44.730671Z","shell.execute_reply.started":"2024-09-28T11:21:44.712291Z","shell.execute_reply":"2024-09-28T11:21:44.730051Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"/kaggle/input/brain-tumor/Brain-tumer/no_tumor/no_tumor (1534).jpg\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Splitting data into train,validation and test","metadata":{}},{"cell_type":"code","source":"# 70% train, 30% temp\ntrain_imgs, temp_imgs, train_labels, temp_labels = train_test_split(images, labels, test_size=0.3, stratify=labels)\n\n# 50% of temp in each test and val\nval_imgs, test_imgs, val_labels, test_labels = train_test_split(temp_imgs, temp_labels, test_size=0.5,stratify=temp_labels)","metadata":{"execution":{"iopub.status.busy":"2024-09-28T11:21:44.731421Z","iopub.execute_input":"2024-09-28T11:21:44.731637Z","iopub.status.idle":"2024-09-28T11:21:44.769028Z","shell.execute_reply.started":"2024-09-28T11:21:44.731614Z","shell.execute_reply":"2024-09-28T11:21:44.768394Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"# Decoding and Preprocessing images ","metadata":{}},{"cell_type":"code","source":"new=tf.io.read_file(images[0])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"new1=tf.io.decode_image(new)","metadata":{"execution":{"iopub.status.busy":"2024-09-28T11:21:48.748222Z","iopub.execute_input":"2024-09-28T11:21:48.748505Z","iopub.status.idle":"2024-09-28T11:21:48.754832Z","shell.execute_reply.started":"2024-09-28T11:21:48.748477Z","shell.execute_reply":"2024-09-28T11:21:48.754036Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"new1.shape","metadata":{"execution":{"iopub.status.busy":"2024-09-28T11:21:48.755786Z","iopub.execute_input":"2024-09-28T11:21:48.756043Z","iopub.status.idle":"2024-09-28T11:21:48.769457Z","shell.execute_reply.started":"2024-09-28T11:21:48.756016Z","shell.execute_reply":"2024-09-28T11:21:48.768779Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"TensorShape([512, 512, 3])"},"metadata":{}}]},{"cell_type":"code","source":"# def simple_preprocess_image(image_path, label):\n#     image = tf.io.read_file(image_path)\n#     image = tf.image.decode_image(image, channels=3)\n#     image = tf.image.resize(image, [224, 224])\n#     image = tf.cast(image, tf.float32) / 255.0\n#     label = tf.cast(label, tf.int64)\n#     return image, label\n\n# def create_tf_dataset(images, labels, batch_size=32, training=False):\n#     dataset = tf.data.Dataset.from_tensor_slices((images, labels))\n#     dataset = dataset.map(lambda x, y: tf.py_function(func=simple_preprocess_image, inp=[x, y], Tout=[tf.float32, tf.int64]))\n#     dataset = dataset.batch(batch_size)\n#     dataset = dataset.shuffle(buffer_size=min(len(images), 1000))\n#     dataset = dataset.prefetch(buffer_size=tf.data.AUTOTUNE)\n#     return dataset\n\n# # Test dataset creation\n# train_data = create_tf_dataset(train_imgs, train_labels, training=True)\n# val_data = create_tf_dataset(val_imgs, val_labels)\n# test_data = create_tf_dataset(test_imgs, test_labels)\n\n# # Inspect shapes\n# batch=train_data[0]:\n# images_batch, labels_batch = batch\n# print(f\"Batch image shape: {images_batch.shape}\")\n# print(f\"Batch label shape: {labels_batch.shape}\")\n","metadata":{"execution":{"iopub.status.busy":"2024-09-28T11:21:48.770251Z","iopub.execute_input":"2024-09-28T11:21:48.770459Z","iopub.status.idle":"2024-09-28T11:21:48.789777Z","shell.execute_reply.started":"2024-09-28T11:21:48.770437Z","shell.execute_reply":"2024-09-28T11:21:48.789164Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"# def create_tf_dataset(images, labels, batch_size=32, training=False):\n#     dataset = tf.data.Dataset.from_generator(\n#         lambda: zip(images, labels),\n#         output_signature=(\n#             tf.TensorSpec(shape=(), dtype=tf.string),  # image_path\n#             tf.TensorSpec(shape=(), dtype=tf.int64)    # label\n#         )\n#     )\n#     dataset = dataset.map(lambda x, y: tf.py_function(preprocess_image, [x, y, training], [tf.float32, tf.int64]))\n#     dataset = dataset.batch(batch_size)\n#     dataset = dataset.shuffle(buffer_size=min(len(images), 1000))  # Use a smaller buffer size for large datasets\n#     dataset = dataset.prefetch(buffer_size=tf.data.AUTOTUNE)\n#     return dataset\n\n# train_data = create_tf_dataset([\"../../../../Projects/Brain_tumor-detection/Data/Brain-tumer\\no_tumor\\no_tumor (6448).jpg\"], train_labels,training=True)# applying data augumentation with training=True\n# val_data = create_tf_dataset(val_imgs, val_labels)\n# test_data = create_tf_dataset(test_imgs, test_labels)","metadata":{"execution":{"iopub.status.busy":"2024-09-28T11:21:48.792082Z","iopub.execute_input":"2024-09-28T11:21:48.792304Z","iopub.status.idle":"2024-09-28T11:21:48.804394Z","shell.execute_reply.started":"2024-09-28T11:21:48.792281Z","shell.execute_reply":"2024-09-28T11:21:48.803733Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"# import os\n# import numpy as np\n# import tensorflow as tf\n# from sklearn.model_selection import train_test_split\n\n# base_dir = \"../../../../Projects/Brain_tumor-detection/Data/Brain-tumer\"\n# categories = ['no_tumor', 'glioma_tumor', 'meningioma_tumor', 'pituitary_tumor']\n# label_map = {'no_tumor': 0, 'glioma_tumor': 1, 'meningioma_tumor': 2, 'pituitary_tumor': 3}\n\n# def load_images(base_dir, label_map):\n#     images = []\n#     labels = []\n#     for category in categories:\n#         category_path = os.path.join(base_dir, category)\n#         label = label_map[category]\n#         for filename in os.listdir(category_path):\n#             if filename.lower().endswith((\".jpg\", \".jpeg\", \".png\")):\n#                 image_path = os.path.join(category_path, filename)\n#                 images.append(image_path)\n#                 labels.append(label)\n#     return images, labels\n\n# images, labels = load_images(base_dir, label_map)\n# combined = list(zip(images, labels))\n# np.random.shuffle(combined)\n# images, labels = zip(*combined)\n\n# train_imgs, temp_imgs, train_labels, temp_labels = train_test_split(images, labels, test_size=0.3, stratify=labels)\n# val_imgs, test_imgs, val_labels, test_labels = train_test_split(temp_imgs, temp_labels, test_size=0.5, stratify=temp_labels)\n\n# def preprocess_image(image_path, label, training=False):\n#     try:\n#         image = tf.io.read_file(image_path)\n#         image = tf.image.decode_image(image, channels=3)\n#         image = tf.image.resize(image, [224, 224])\n        \n#         if training:\n#             image = tf.image.random_flip_left_right(image)\n#             image = tf.image.random_brightness(image, max_delta=0.2)\n#             image = tf.image.random_contrast(image, lower=0.8, upper=1.2)\n#             image = tf.image.random_saturation(image, lower=0.8, upper=1.2)\n\n#         image = tf.cast(image, tf.float32) / 255.0\n#         label = tf.cast(label, tf.int64)\n#         return image, label\n#     except Exception as e:\n#         print(f\"Error processing image {image_path}: {e}\")\n#         return tf.zeros([224, 224, 3]), tf.constant(-1)\n\n# def create_tf_dataset(images, labels, batch_size=32, training=False):\n#     dataset = tf.data.Dataset.from_generator(\n#         lambda: zip(images, labels),\n#         output_signature=(\n#             tf.TensorSpec(shape=(), dtype=tf.string),  # image_path\n#             tf.TensorSpec(shape=(), dtype=tf.int64)    # label\n#         )\n#     )\n#     dataset = dataset.map(lambda x, y: tf.py_function(preprocess_image, [x, y, training], [tf.float32, tf.int64]))\n#     dataset = dataset.batch(batch_size)\n#     dataset = dataset.shuffle(buffer_size=min(len(images), 1000))  # Use a smaller buffer size for large datasets\n#     dataset = dataset.prefetch(buffer_size=tf.data.AUTOTUNE)\n#     return dataset\n\n# train_data = create_tf_dataset(train_imgs, train_labels, training=True)\n# val_data = create_tf_dataset(val_imgs, val_labels)\n# test_data = create_tf_dataset(test_imgs, test_labels)\n","metadata":{"execution":{"iopub.status.busy":"2024-09-28T11:21:48.805411Z","iopub.execute_input":"2024-09-28T11:21:48.805676Z","iopub.status.idle":"2024-09-28T11:21:48.819422Z","shell.execute_reply.started":"2024-09-28T11:21:48.805651Z","shell.execute_reply":"2024-09-28T11:21:48.818806Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"from PIL import Image\nimport numpy as np\nimport tensorflow as tf\n\ndef preprocess_image_pillow(image_path, label, training=False):\n    # Open the image using Pillow\n    image = Image.open(image_path).convert('RGB')  # Convert to RGB\n    # Resize the image\n    image = image.resize((224,224))\n    # Convert the image to a numpy array\n    image_array = np.array(image)\n    # Normalize the image to [0, 1]\n    image_array = image_array / 255.0\n    # Convert the numpy array to a TensorFlow tensor\n    image_tensor = tf.convert_to_tensor(image_array, dtype=tf.float32)\n    # Ensure label is of correct type\n    label_tensor = tf.convert_to_tensor(label, dtype=tf.int64)\n    \n    # Add a batch dimension\n    image_tensor = tf.expand_dims(image_tensor, axis=0)\n\n    if training:\n        # Apply data augmentation\n        # Random flip left-right\n        image_tensor = tf.image.random_flip_left_right(image_tensor)\n        # Random flip up-down\n        image_tensor = tf.image.random_flip_up_down(image_tensor)\n        # Random rotation (0, 90, 180, 270 degrees)\n        angles = [0, 90, 180, 270]\n        angle = tf.random.uniform([], minval=0, maxval=4, dtype=tf.int32)\n        image_tensor = tf.image.rot90(image_tensor, k=angle)\n        # Random brightness\n        image_tensor = tf.image.random_brightness(image_tensor, max_delta=0.2)\n        # Random contrast\n        image_tensor = tf.image.random_contrast(image_tensor, lower=0.7, upper=1.3)\n        # Random saturation\n        image_tensor = tf.image.random_saturation(image_tensor, lower=0.7, upper=1.3)\n\n    # Remove batch dimension before returning\n    image_tensor = tf.squeeze(image_tensor, axis=0)\n\n    return image_tensor, label_tensor\n","metadata":{"execution":{"iopub.status.busy":"2024-09-28T11:21:48.820145Z","iopub.execute_input":"2024-09-28T11:21:48.820382Z","iopub.status.idle":"2024-09-28T11:21:48.833353Z","shell.execute_reply.started":"2024-09-28T11:21:48.820358Z","shell.execute_reply":"2024-09-28T11:21:48.832683Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"def generate_dataset(images, labels, training=False):\n    for img_path, lbl in zip(images, labels):\n        image_tensor, label_tensor = preprocess_image_pillow(img_path, lbl, training)\n        yield image_tensor, label_tensor\n\ndef create_tf_dataset(images, labels, batch_size=64,training=False):\n    dataset = tf.data.Dataset.from_generator(\n        lambda: generate_dataset(images, labels, training),\n        output_signature=(\n            tf.TensorSpec(shape=[224,224,3], dtype=tf.float32),\n            tf.TensorSpec(shape=[], dtype=tf.int64)\n        )\n    )\n    dataset = dataset.batch(batch_size=batch_size)\n    dataset = dataset.shuffle(buffer_size=min(len(images), 1000))\n#     dataset = dataset.prefetch(buffer_size=tf.data.AUTOTUNE)\n    return dataset\n\n# Test the dataset creation\ntrain_data = create_tf_dataset(train_imgs, train_labels, training=True)\nval_data = create_tf_dataset(val_imgs, val_labels)\ntest_data = create_tf_dataset(test_imgs, test_labels)\n\ndef split_images_labels(dataset):\n    images = []\n    labels = []\n    \n    for image_batch, label_batch in dataset:\n        images.append(image_batch)\n        labels.append(label_batch)\n    \n    # Concatenate all batches into a single tensor\n    return tf.concat(images, axis=0), tf.concat(labels, axis=0)\n\n\n# Split train_data into separate images and labels\ntrain_images, train_labels = split_images_labels(train_data)\nval_images, val_labels = split_images_labels(val_data)\ntest_images, test_labels = split_images_labels(test_data)","metadata":{"execution":{"iopub.status.busy":"2024-09-28T11:21:48.834181Z","iopub.execute_input":"2024-09-28T11:21:48.834416Z","iopub.status.idle":"2024-09-28T11:21:48.929986Z","shell.execute_reply.started":"2024-09-28T11:21:48.834393Z","shell.execute_reply":"2024-09-28T11:21:48.929263Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":"# Custom Classification model","metadata":{}},{"cell_type":"markdown","source":"# importing model","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.applications import ResNet50V2\nfrom tensorflow.keras.layers import Dense , GlobalAveragePooling2D\nfrom tensorflow.keras.models import Model","metadata":{"execution":{"iopub.status.busy":"2024-09-28T11:21:48.930828Z","iopub.execute_input":"2024-09-28T11:21:48.931051Z","iopub.status.idle":"2024-09-28T11:21:48.959601Z","shell.execute_reply.started":"2024-09-28T11:21:48.931029Z","shell.execute_reply":"2024-09-28T11:21:48.958997Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":"# Adding custom layers","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.layers import Dense, Dropout, MaxPooling2D, Conv2D, BatchNormalization, Flatten\nfrom tensorflow.keras.models import Sequential\n\nmodel = Sequential()\n\n# 1st conv block\nmodel.add(Conv2D(32, (3, 3), padding=\"same\", data_format=\"channels_last\", activation=\"relu\"))\n\n# 3rd conv block\nmodel.add(Conv2D(256, (2, 2), activation=\"selu\"))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n\n# 4th conv block\nmodel.add(Conv2D(512, (2, 2), activation=\"selu\"))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n\n# Dense block\nmodel.add(Flatten())\n\n# Dense block 1\nmodel.add(Dense(3000, activation=\"selu\"))\n\n# Dense block 2\nmodel.add(Dense(512, activation=\"selu\"))\n\n# Dense block 5\nmodel.add(Dense(64, activation=\"selu\"))\nmodel.add(Dropout(0.2))\n\n# Output layer\nmodel.add(Dense(4, activation=\"softmax\"))\n","metadata":{"execution":{"iopub.status.busy":"2024-09-28T11:21:48.960388Z","iopub.execute_input":"2024-09-28T11:21:48.960613Z","iopub.status.idle":"2024-09-28T11:21:48.964014Z","shell.execute_reply.started":"2024-09-28T11:21:48.960591Z","shell.execute_reply":"2024-09-28T11:21:48.963399Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":"# compiling a model","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.optimizers import Adam","metadata":{"execution":{"iopub.status.busy":"2024-09-28T11:21:48.964762Z","iopub.execute_input":"2024-09-28T11:21:48.964992Z","iopub.status.idle":"2024-09-28T11:21:48.977894Z","shell.execute_reply.started":"2024-09-28T11:21:48.964970Z","shell.execute_reply":"2024-09-28T11:21:48.977232Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":"# Training a model","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, LearningRateScheduler\nfrom tensorflow.keras.optimizers import Adam\n\nearly_stopping = EarlyStopping(\n    monitor='val_loss',\n    patience=3,  # Stop if no improvement for 3 epochs\n    verbose=1,\n    restore_best_weights=True\n)\n\n# Define model checkpoint\nmodel_checkpoint = ModelCheckpoint(\n    'best_model.keras',\n    monitor='val_loss',\n    save_best_only=True,\n    verbose=1\n)\n\noptimizer=Adam(learning_rate=0.001)\n\n# Define learning rate scheduler\n\n\nmodel.compile(optimizer=optimizer,\n              loss='sparse_categorical_crossentropy',  # Use 'categorical_crossentropy' for multi-class\n               metrics=['accuracy'])\n\n# Fit the model with the callbacks\nhistory=model.fit(\n    train_data,\n    validation_data=val_data,\n    epochs=10,  # Start with 30 epochs\n#      steps_per_epoch=1,  # As specified\n    callbacks=[early_stopping\n               , model_checkpoint\n              ]\n)\n","metadata":{"execution":{"iopub.status.busy":"2024-09-28T11:21:48.978680Z","iopub.execute_input":"2024-09-28T11:21:48.979100Z","iopub.status.idle":"2024-09-28T11:21:48.985301Z","shell.execute_reply.started":"2024-09-28T11:21:48.979074Z","shell.execute_reply":"2024-09-28T11:21:48.984623Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":"# For training on Kaggle TPU","metadata":{}},{"cell_type":"code","source":"# import tensorflow as tf\n# from tensorflow.keras.models import Model\n# from tensorflow.keras.layers import GlobalAveragePooling2D, Dense,Dropout\n# from tensorflow.keras.layers import Conv2D, MaxPooling2D, BatchNormalization, Flatten, Dense\n\n# from tensorflow.keras.models import Sequential\n# from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, LearningRateScheduler\n\n\n# # Detect and initialize the TPU\n# tpu = tf.distribute.cluster_resolver.TPUClusterResolver()  # Detect the TPU hardware\n# tf.tpu.experimental.initialize_tpu_system(tpu)  # Initialize the TPU system\n\n# # Instantiate the TPU distribution strategy\n# tpu_strategy = tf.distribute.TPUStrategy(tpu)\n\n# # Define the model within the TPU strategy scope\n# with tpu_strategy.scope():\n#     # Assuming you have a pre-trained base model (like MobileNet, EfficientNet, etc.)\n    \n\n\n#     model = Sequential()\n\n#     # 1st conv block\n#     model.add(Conv2D(176, (5,5), padding=\"same\", data_format=\"channels_last\", activation=\"relu\"))\n#     model.add(MaxPooling2D(pool_size=(5,5)))  # Adding pooling after the first conv block\n\n#     # 2nd conv block\n#     model.add(Conv2D(384, (3,3), activation=\"relu\"))\n#     model.add(BatchNormalization())\n#     model.add(MaxPooling2D(pool_size=(5,5)))\n\n#     # 3rd conv block\n#     model.add(Conv2D(288, (3,3), activation=\"relu\"))\n#     model.add(BatchNormalization())\n#     model.add(MaxPooling2D(pool_size=(5,5)))\n\n#     # Dense block\n#     model.add(Flatten())\n\n#     # Fully connected block 1\n#     model.add(Dense(400, activation=\"relu\"))\n#     model.add(Dropout(0.2))  # Using AlphaDropout\n\n#     # Fully connected block 2\n#     model.add(Dense(64, activation=\"relu\"))\n#     model.add(Dropout(0.2))  # Using AlphaDropout\n\n#     # Output layer\n#     model.add(Dense(4, activation=\"softmax\"))  # 4 classes for multiclass classification\n\n\n\n    \n#     early_stopping = EarlyStopping(\n#     monitor='val_loss',\n#     patience=3,  # Stop if no improvement for 3 epochs\n#     verbose=1,\n#     restore_best_weights=True\n#     )\n    \n#     model_checkpoint = ModelCheckpoint(\n#     'custom_model.keras',\n#     monitor='val_loss',\n#     save_best_only=True,\n#     verbose=1\n#     )\n    \n#     optimizer=Adam(learning_rate=0.00036659)\n\n#     # Compile the model with optimizer, loss function, and metrics\n#     model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n\n#     # Train the model normally\n#     model.fit(train_data, \n#               epochs=30,\n#               validation_data=val_data, \n#                callbacks=[early_stopping,model_checkpoint]\n#     #           steps_per_epoch=1500\n#              )\n","metadata":{"execution":{"iopub.status.busy":"2024-09-28T11:21:49.007414Z","iopub.execute_input":"2024-09-28T11:21:49.007684Z","iopub.status.idle":"2024-09-28T13:01:48.039103Z","shell.execute_reply.started":"2024-09-28T11:21:49.007661Z","shell.execute_reply":"2024-09-28T13:01:48.037970Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":20,"outputs":[{"name":"stdout","text":"INFO:tensorflow:Deallocate tpu buffers before initializing tpu system.\nINFO:tensorflow:Initializing the TPU system: local\nINFO:tensorflow:Finished initializing TPU system.\nINFO:tensorflow:Found TPU system:\nINFO:tensorflow:*** Num TPU Cores: 8\nINFO:tensorflow:*** Num TPU Workers: 1\nINFO:tensorflow:*** Num TPU Cores Per Worker: 8\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:0, TPU, 0, 0)\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:1, TPU, 0, 0)\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:2, TPU, 0, 0)\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:3, TPU, 0, 0)\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:4, TPU, 0, 0)\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:5, TPU, 0, 0)\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:6, TPU, 0, 0)\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:7, TPU, 0, 0)\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n","output_type":"stream"},{"name":"stderr","text":"I0000 00:00:1727522513.378007      13 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/30\n","output_type":"stream"},{"name":"stderr","text":"2024-09-28 11:30:52.740729: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:961] model_pruner failed: INVALID_ARGUMENT: Graph does not contain terminal node StatefulPartitionedCall.\nI0000 00:00:1727523380.468359     834 tpu_compilation_cache_interface.cc:441] TPU host compilation cache miss: cache_key(330c04c90a4943ee:0:0), session_name()\n","output_type":"stream"},{"name":"stdout","text":"      3/Unknown \u001b[1m342s\u001b[0m 65ms/step - accuracy: 0.1736 - loss: 3.1374  ","output_type":"stream"},{"name":"stderr","text":"I0000 00:00:1727523392.607582     834 tpu_compile_op_common.cc:245] Compilation of 330c04c90a4943ee:0:0 with session name  took 12.139174751s and succeeded\nI0000 00:00:1727523392.623928     834 tpu_compilation_cache_interface.cc:475] TPU host compilation cache: compilation complete for cache_key(330c04c90a4943ee:0:0), session_name(), subgraph_key(std::string(property.function_name) = \"cluster_one_step_on_iterator_4481373864356803050\", property.function_library_fingerprint = 8829829481548384851, property.mlir_module_fingerprint = 0, property.num_replicas = 8, topology.chip_bounds().x = 2, topology.chip_bounds().y = 2, topology.chip_bounds().z = 1, topology.wrap().x = false, topology.wrap().y = false, topology.wrap().z = false, std::string(property.shapes_prefix) = \"8,224,224,3,;8,;\", property.guaranteed_constants_size = 0, embedding_partitions_fingerprint = \"1688352644216761960\")\nI0000 00:00:1727523392.623972     834 tpu_compilation_cache_interface.cc:541] After adding entry for key 330c04c90a4943ee:0:0 with session_name  cache is 1 entries (22753051 bytes),  marked for eviction 0 entries (0 bytes).\n","output_type":"stream"},{"name":"stdout","text":"    376/Unknown \u001b[1m356s\u001b[0m 39ms/step - accuracy: 0.5034 - loss: 1.2166","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/contextlib.py:153: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n  self.gen.throw(typ, value, traceback)\n2024-09-28 11:38:12.309418: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:961] model_pruner failed: INVALID_ARGUMENT: Graph does not contain terminal node Add/ReadVariableOp.\nI0000 00:00:1727523525.223859     765 tpu_compilation_cache_interface.cc:441] TPU host compilation cache miss: cache_key(1b40c4d2878bcec3:0:0), session_name()\nI0000 00:00:1727523534.326503     765 tpu_compile_op_common.cc:245] Compilation of 1b40c4d2878bcec3:0:0 with session name  took 9.102596233s and succeeded\nI0000 00:00:1727523534.328802     765 tpu_compilation_cache_interface.cc:475] TPU host compilation cache: compilation complete for cache_key(1b40c4d2878bcec3:0:0), session_name(), subgraph_key(std::string(property.function_name) = \"cluster_one_step_on_iterator_10592228204744772439\", property.function_library_fingerprint = 16558484865409399794, property.mlir_module_fingerprint = 0, property.num_replicas = 8, topology.chip_bounds().x = 2, topology.chip_bounds().y = 2, topology.chip_bounds().z = 1, topology.wrap().x = false, topology.wrap().y = false, topology.wrap().z = false, std::string(property.shapes_prefix) = \"8,224,224,3,;8,;\", property.guaranteed_constants_size = 0, embedding_partitions_fingerprint = \"1688352644216761960\")\nI0000 00:00:1727523534.328824     765 tpu_compilation_cache_interface.cc:541] After adding entry for key 1b40c4d2878bcec3:0:0 with session_name  cache is 2 entries (27117613 bytes),  marked for eviction 0 entries (0 bytes).\nI0000 00:00:1727523536.096087     753 tpu_compilation_cache_interface.cc:441] TPU host compilation cache miss: cache_key(360106632582ddce:0:0), session_name()\nI0000 00:00:1727523544.892667     753 tpu_compile_op_common.cc:245] Compilation of 360106632582ddce:0:0 with session name  took 8.796542217s and succeeded\nI0000 00:00:1727523544.895041     753 tpu_compilation_cache_interface.cc:475] TPU host compilation cache: compilation complete for cache_key(360106632582ddce:0:0), session_name(), subgraph_key(std::string(property.function_name) = \"cluster_one_step_on_iterator_10592228204744772439\", property.function_library_fingerprint = 16558484865409399794, property.mlir_module_fingerprint = 0, property.num_replicas = 8, topology.chip_bounds().x = 2, topology.chip_bounds().y = 2, topology.chip_bounds().z = 1, topology.wrap().x = false, topology.wrap().y = false, topology.wrap().z = false, std::string(property.shapes_prefix) = \"7,224,224,3,;7,;\", property.guaranteed_constants_size = 0, embedding_partitions_fingerprint = \"1688352644216761960\")\nI0000 00:00:1727523544.895067     753 tpu_compilation_cache_interface.cc:541] After adding entry for key 360106632582ddce:0:0 with session_name  cache is 3 entries (31637931 bytes),  marked for eviction 0 entries (0 bytes).\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1: val_loss improved from inf to 1.00181, saving model to custom_model.keras\n\u001b[1m377/377\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m495s\u001b[0m 407ms/step - accuracy: 0.5038 - loss: 1.2156 - val_accuracy: 0.5951 - val_loss: 1.0018\nEpoch 2/30\n\u001b[1m376/377\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.7122 - loss: 0.7247\nEpoch 2: val_loss improved from 1.00181 to 0.74327, saving model to custom_model.keras\n\u001b[1m377/377\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m407s\u001b[0m 225ms/step - accuracy: 0.7123 - loss: 0.7245 - val_accuracy: 0.6801 - val_loss: 0.7433\nEpoch 3/30\n\u001b[1m377/377\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.7870 - loss: 0.5759\nEpoch 3: val_loss improved from 0.74327 to 0.50107, saving model to custom_model.keras\n\u001b[1m377/377\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m412s\u001b[0m 217ms/step - accuracy: 0.7870 - loss: 0.5759 - val_accuracy: 0.8161 - val_loss: 0.5011\nEpoch 4/30\n\u001b[1m377/377\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.8297 - loss: 0.4736\nEpoch 4: val_loss improved from 0.50107 to 0.38254, saving model to custom_model.keras\n\u001b[1m377/377\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m405s\u001b[0m 219ms/step - accuracy: 0.8297 - loss: 0.4736 - val_accuracy: 0.8686 - val_loss: 0.3825\nEpoch 5/30\n\u001b[1m377/377\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.8530 - loss: 0.3999\nEpoch 5: val_loss did not improve from 0.38254\n\u001b[1m377/377\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m405s\u001b[0m 216ms/step - accuracy: 0.8529 - loss: 0.3999 - val_accuracy: 0.8331 - val_loss: 0.3948\nEpoch 6/30\n\u001b[1m377/377\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.8577 - loss: 0.3864\nEpoch 6: val_loss improved from 0.38254 to 0.31360, saving model to custom_model.keras\n\u001b[1m377/377\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m416s\u001b[0m 219ms/step - accuracy: 0.8577 - loss: 0.3864 - val_accuracy: 0.8949 - val_loss: 0.3136\nEpoch 7/30\n\u001b[1m377/377\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.8811 - loss: 0.3252\nEpoch 7: val_loss improved from 0.31360 to 0.31294, saving model to custom_model.keras\n\u001b[1m377/377\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m427s\u001b[0m 266ms/step - accuracy: 0.8811 - loss: 0.3251 - val_accuracy: 0.8856 - val_loss: 0.3129\nEpoch 8/30\n\u001b[1m377/377\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.8912 - loss: 0.3122\nEpoch 8: val_loss improved from 0.31294 to 0.27333, saving model to custom_model.keras\n\u001b[1m377/377\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m402s\u001b[0m 218ms/step - accuracy: 0.8912 - loss: 0.3122 - val_accuracy: 0.9011 - val_loss: 0.2733\nEpoch 9/30\n\u001b[1m376/377\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.8988 - loss: 0.2758\nEpoch 9: val_loss improved from 0.27333 to 0.21626, saving model to custom_model.keras\n\u001b[1m377/377\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m402s\u001b[0m 216ms/step - accuracy: 0.8988 - loss: 0.2757 - val_accuracy: 0.9181 - val_loss: 0.2163\nEpoch 10/30\n\u001b[1m376/377\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9057 - loss: 0.2386\nEpoch 10: val_loss improved from 0.21626 to 0.20948, saving model to custom_model.keras\n\u001b[1m377/377\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m403s\u001b[0m 222ms/step - accuracy: 0.9057 - loss: 0.2386 - val_accuracy: 0.9289 - val_loss: 0.2095\nEpoch 11/30\n\u001b[1m377/377\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9270 - loss: 0.2164\nEpoch 11: val_loss did not improve from 0.20948\n\u001b[1m377/377\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m429s\u001b[0m 223ms/step - accuracy: 0.9270 - loss: 0.2164 - val_accuracy: 0.9165 - val_loss: 0.2728\nEpoch 12/30\n\u001b[1m376/377\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9211 - loss: 0.2090\nEpoch 12: val_loss did not improve from 0.20948\n\u001b[1m377/377\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m438s\u001b[0m 219ms/step - accuracy: 0.9211 - loss: 0.2091 - val_accuracy: 0.9304 - val_loss: 0.2263\nEpoch 13/30\n\u001b[1m376/377\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.9380 - loss: 0.1911\nEpoch 13: val_loss did not improve from 0.20948\n\u001b[1m377/377\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m418s\u001b[0m 227ms/step - accuracy: 0.9380 - loss: 0.1911 - val_accuracy: 0.9011 - val_loss: 0.2625\nEpoch 13: early stopping\nRestoring model weights from the end of the best epoch: 10.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Hyperparameter tuning using 'keras-tuner'","metadata":{}},{"cell_type":"code","source":"# !pip install keras-tuner","metadata":{"execution":{"iopub.status.busy":"2024-09-28T13:01:48.041631Z","iopub.execute_input":"2024-09-28T13:01:48.041924Z","iopub.status.idle":"2024-09-28T13:01:48.045900Z","shell.execute_reply.started":"2024-09-28T13:01:48.041897Z","shell.execute_reply":"2024-09-28T13:01:48.045074Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"# from keras_tuner import RandomSearch\n# from keras_tuner.engine.hyperparameters import HyperParameters\n# from tensorflow import keras","metadata":{"execution":{"iopub.status.busy":"2024-09-28T13:01:48.046819Z","iopub.execute_input":"2024-09-28T13:01:48.047085Z","iopub.status.idle":"2024-09-28T13:01:48.056419Z","shell.execute_reply.started":"2024-09-28T13:01:48.047057Z","shell.execute_reply":"2024-09-28T13:01:48.055589Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"# import tensorflow as tf\n# from tensorflow.keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D, BatchNormalization\n# from tensorflow.keras.models import Sequential\n# from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n# from keras_tuner import RandomSearch\n\n# # # Detect and initialize the TPU\n# # tpu = tf.distribute.cluster_resolver.TPUClusterResolver()  # Detect the TPU hardware\n# # tf.tpu.experimental.initialize_tpu_system(tpu)  # Initialize the TPU system\n\n# # # Instantiate the TPU distribution strategy\n# # tpu_strategy = tf.distribute.TPUStrategy(tpu)\n\n\n# # Define the model building function for Keras Tuner\n# def build_model(hp):\n#     model = Sequential()\n\n#     # First conv block\n#     model.add(Conv2D(\n#         filters=hp.Int(\"conv_1_filters\", min_value=32, max_value=512, step=16),\n#         kernel_size=hp.Choice(\"conv_1_kernel\", values=[3, 5]),\n#         padding=\"same\",\n#         activation=hp.Choice(\"activation\", [\"relu\", \"selu\"]),\n#         input_shape=(224, 224, 3)\n#     ))\n#     model.add(MaxPooling2D(pool_size=hp.Choice(\"pool_1_size\", values=[2, 3, 5])))\n\n#     # Second conv block\n#     model.add(Conv2D(\n#         filters=hp.Int(\"conv_2_filters\", min_value=32, max_value=512, step=16),\n#         kernel_size=hp.Choice(\"conv_2_kernel\", values=[3, 5]),\n#         activation=hp.Choice(\"activation\", [\"relu\", \"selu\"])\n#     ))\n#     model.add(MaxPooling2D(pool_size=hp.Choice(\"pool_2_size\", values=[2, 3, 5])))\n\n#     # Third conv block\n#     model.add(Conv2D(\n#         filters=hp.Int(\"conv_3_filters\", min_value=64, max_value=512, step=16),\n#         kernel_size=hp.Choice(\"conv_3_kernel\", values=[3, 5]),\n#         activation=hp.Choice(\"activation\", [\"relu\", \"selu\"])\n#     ))\n#     model.add(MaxPooling2D(pool_size=hp.Choice(\"pool_3_size\", values=[2, 3, 5])))\n\n#     # Dense block\n#     model.add(Flatten())\n#     model.add(Dense(\n#         units=hp.Int(\"dense_1_neurons\", min_value=32, max_value=512, step=16),\n#         activation=hp.Choice(\"activation\", [\"relu\", \"selu\"])\n#     ))\n\n#     if hp.Boolean(\"dropout\"):\n#         model.add(Dropout(rate=hp.Choice(\"dropout_1\", values=[0.2, 0.3, 0.5])))\n\n#     model.add(Dense(\n#         units=hp.Int(\"dense_2_neurons\", min_value=32, max_value=512, step=16),\n#         activation=hp.Choice(\"activation\", [\"relu\", \"selu\"])\n#     ))\n\n#     if hp.Boolean(\"dropout\"):\n#         model.add(Dropout(rate=hp.Choice(\"dropout_2\", values=[0.2, 0.3, 0.5])))\n\n#     # Output layer\n#     model.add(Dense(4, activation=\"softmax\"))  # 4 classes for multiclass classification\n\n#     # Learning rate\n#     learning_rate = hp.Float(\"lr\", min_value=1e-5, max_value=1e-1, sampling=\"log\")\n\n#     model.compile(\n#         optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n#         loss=\"sparse_categorical_crossentropy\",\n#         metrics=[\"accuracy\"]\n#     )\n#     return model\n\n# # Define the Keras Tuner search\n# # with tpu_strategy.scope():\n# tuner = RandomSearch(\n#         build_model,\n#         objective=\"val_loss\",\n#         max_trials=10,\n# #         executions_per_trial=5,\n#         directory=\"output\",\n#         project_name=\"custom_tuned_model\"\n#     )\n\n    \n    \n","metadata":{"execution":{"iopub.status.busy":"2024-09-28T13:01:48.057384Z","iopub.execute_input":"2024-09-28T13:01:48.057630Z","iopub.status.idle":"2024-09-28T13:01:48.066022Z","shell.execute_reply.started":"2024-09-28T13:01:48.057605Z","shell.execute_reply":"2024-09-28T13:01:48.065116Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"# with tpu_strategy.scope():\n# tuner.search(train_data,epochs=3,validation_data=val_data)","metadata":{"execution":{"iopub.status.busy":"2024-09-28T13:01:48.067022Z","iopub.execute_input":"2024-09-28T13:01:48.067267Z","iopub.status.idle":"2024-09-28T13:01:48.075643Z","shell.execute_reply.started":"2024-09-28T13:01:48.067242Z","shell.execute_reply":"2024-09-28T13:01:48.074924Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"\n# best_model = tuner.get_best_models(num_models=1)[0]\n","metadata":{"execution":{"iopub.status.busy":"2024-09-28T13:01:48.076602Z","iopub.execute_input":"2024-09-28T13:01:48.077382Z","iopub.status.idle":"2024-09-28T13:01:48.083924Z","shell.execute_reply.started":"2024-09-28T13:01:48.077353Z","shell.execute_reply":"2024-09-28T13:01:48.082909Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"\nmodel.save(\"custom_model.keras\")","metadata":{"execution":{"iopub.status.busy":"2024-09-28T13:01:48.085053Z","iopub.execute_input":"2024-09-28T13:01:48.085337Z","iopub.status.idle":"2024-09-28T13:01:48.092109Z","shell.execute_reply.started":"2024-09-28T13:01:48.085312Z","shell.execute_reply":"2024-09-28T13:01:48.091291Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"markdown","source":"# Evaluation","metadata":{}},{"cell_type":"code","source":"\nmodel.evaluate(test_data)","metadata":{"execution":{"iopub.status.busy":"2024-09-28T13:01:48.103682Z","iopub.execute_input":"2024-09-28T13:01:48.103957Z","iopub.status.idle":"2024-09-28T13:03:41.265389Z","shell.execute_reply.started":"2024-09-28T13:01:48.103930Z","shell.execute_reply":"2024-09-28T13:03:41.264399Z"},"trusted":true},"execution_count":28,"outputs":[{"name":"stderr","text":"2024-09-28 13:03:06.111085: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:961] model_pruner failed: INVALID_ARGUMENT: Graph does not contain terminal node Add/ReadVariableOp.\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m81/81\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 27ms/step - accuracy: 0.9261 - loss: 0.1954\n","output_type":"stream"},{"execution_count":28,"output_type":"execute_result","data":{"text/plain":"[0.19542238116264343, 0.931993842124939]"},"metadata":{}}]},{"cell_type":"markdown","source":"# F1 score","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport tensorflow as tf\nfrom sklearn.metrics import f1_score\n\n\ntrue_labels = []\npredicted_classes = []\n\nfor x_batch, y_batch in test_data:\n    # Make predictions\n    predictions = model.predict(x_batch)\n    predicted_classes_batch = np.argmax(predictions, axis=1)\n    \n    # Collect true labels and predicted classes\n    true_labels.extend(y_batch.numpy())\n    predicted_classes.extend(predicted_classes_batch)\n\n# Calculate F1 score\nf1 = f1_score(true_labels, predicted_classes, average='weighted')\nprint(f'F1 Score: {f1}')\n","metadata":{"execution":{"iopub.status.busy":"2024-09-28T13:06:00.556925Z","iopub.execute_input":"2024-09-28T13:06:00.557347Z","iopub.status.idle":"2024-09-28T13:07:33.868495Z","shell.execute_reply.started":"2024-09-28T13:06:00.557316Z","shell.execute_reply":"2024-09-28T13:07:33.867488Z"},"trusted":true},"execution_count":30,"outputs":[{"name":"stderr","text":"2024-09-28 13:06:33.920821: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:961] model_pruner failed: INVALID_ARGUMENT: Graph does not contain terminal node sequential_1/batch_normalization_1/Cast/ReadVariableOp.\nI0000 00:00:1727528793.959887     824 tpu_compilation_cache_interface.cc:441] TPU host compilation cache miss: cache_key(b6680d3e1ceb04ce:0:0), session_name()\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step\n","output_type":"stream"},{"name":"stderr","text":"I0000 00:00:1727528799.371423     824 tpu_compile_op_common.cc:245] Compilation of b6680d3e1ceb04ce:0:0 with session name  took 5.411487767s and succeeded\nI0000 00:00:1727528799.372484     824 tpu_compilation_cache_interface.cc:475] TPU host compilation cache: compilation complete for cache_key(b6680d3e1ceb04ce:0:0), session_name(), subgraph_key(std::string(property.function_name) = \"cluster_one_step_on_data_distributed_14064117965600666294\", property.function_library_fingerprint = 591476631238207793, property.mlir_module_fingerprint = 0, property.num_replicas = 8, topology.chip_bounds().x = 2, topology.chip_bounds().y = 2, topology.chip_bounds().z = 1, topology.wrap().x = false, topology.wrap().y = false, topology.wrap().z = false, std::string(property.shapes_prefix) = \"\", property.guaranteed_constants_size = 0, embedding_partitions_fingerprint = \"1688352644216761960\")\nI0000 00:00:1727528799.372514     824 tpu_compilation_cache_interface.cc:541] After adding entry for key b6680d3e1ceb04ce:0:0 with session_name  cache is 4 entries (34530225 bytes),  marked for eviction 0 entries (0 bytes).\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step \n\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step \n\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step \n\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step \n\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step \n\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step \n\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step \n\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step \n\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step \n\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step \n\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step \n\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step \n\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step \n\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step \n\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step \n\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step \n\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step \n\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step \n\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step \n\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step \n\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step \n\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step \n\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step  \n\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step \n\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step \n\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step \n\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step \n\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step \n\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step \n\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step \n\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step \n\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step \n\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step \n\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step \n\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step \n\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step \n\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step \n\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step \n\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step \n\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step \n\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step \n\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step \n\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step \n\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step \n\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step \n\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step \n\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step \n\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step \n\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step \n\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step \n\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step \n\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step \n\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step \n\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step \n\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step  \n\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step \n\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step  \n\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step  \n\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step  \n\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step \n\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step \n\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step \n\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step \n\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step  \n\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step \n\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step \n\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step \n\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step \n\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step \n\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step \n\u001b[1m1/2\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 529ms/step","output_type":"stream"},{"name":"stderr","text":"I0000 00:00:1727528843.275688     778 tpu_compilation_cache_interface.cc:441] TPU host compilation cache miss: cache_key(3f3a7e145a44ce80:0:0), session_name()\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6s/step  \n","output_type":"stream"},{"name":"stderr","text":"I0000 00:00:1727528848.558706     778 tpu_compile_op_common.cc:245] Compilation of 3f3a7e145a44ce80:0:0 with session name  took 5.282981187s and succeeded\nI0000 00:00:1727528848.559822     778 tpu_compilation_cache_interface.cc:475] TPU host compilation cache: compilation complete for cache_key(3f3a7e145a44ce80:0:0), session_name(), subgraph_key(std::string(property.function_name) = \"cluster_one_step_on_data_distributed_16563015463115862531\", property.function_library_fingerprint = 11574320054172422790, property.mlir_module_fingerprint = 0, property.num_replicas = 8, topology.chip_bounds().x = 2, topology.chip_bounds().y = 2, topology.chip_bounds().z = 1, topology.wrap().x = false, topology.wrap().y = false, topology.wrap().z = false, std::string(property.shapes_prefix) = \"3,224,224,3,;\", property.guaranteed_constants_size = 0, embedding_partitions_fingerprint = \"1688352644216761960\")\nI0000 00:00:1727528848.559846     778 tpu_compilation_cache_interface.cc:541] After adding entry for key 3f3a7e145a44ce80:0:0 with session_name  cache is 5 entries (37532109 bytes),  marked for eviction 0 entries (0 bytes).\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step  \n\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step \n\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step  \n\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step  \n\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step  \n\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step \n\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step  \n\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step  \n\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step \nF1 Score: 0.9254915763709917\n","output_type":"stream"}]}]}